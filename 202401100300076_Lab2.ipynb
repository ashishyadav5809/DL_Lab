{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ad1L43zcuzVI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "def sigmoid_derivative(x):\n",
        "      s = sigmoid(x)\n",
        "      return s * (1 - s)"
      ],
      "metadata": {
        "id": "abM1DwoS33Mv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_dataset():\n",
        "  X = np.array([\n",
        "            [0, 0],\n",
        "            [0, 1],\n",
        "            [1, 0],\n",
        "            [1, 1]\n",
        "                                        ])\n",
        "  y = np.array([[0], [1], [1], [0]])\n",
        "  return X, y\n",
        "X, y = initialize_dataset()\n",
        "print(\"X:\\n\", X)\n",
        "print(\"y:\\n\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG57fGRg3_WT",
        "outputId": "f902f6f9-ebb9-4e5f-d60e-533e12ac9986"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:\n",
            " [[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n",
            "y:\n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters(n_input, n_hidden, n_output):\n",
        "\n",
        "          # Input → Hidden\n",
        "              W1 = np.random.randn(n_input, n_hidden) * 0.01\n",
        "              b1 = np.zeros((1, n_hidden))\n",
        "\n",
        "                          # Hidden → Output\n",
        "              W2 = np.random.randn(n_hidden, n_output) * 0.01\n",
        "              b2 = np.zeros((1, n_output))\n",
        "\n",
        "              parameters = {\n",
        "                               \"W1\": W1,\n",
        "                               \"b1\": b1,\n",
        "                               \"W2\": W2,\n",
        "                               \"b2\": b2\n",
        "                                                                              }\n",
        "\n",
        "              return parameters"
      ],
      "metadata": {
        "id": "TDIqTTIs5QWA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, parameters):\n",
        "\n",
        "          W1 = parameters[\"W1\"]\n",
        "          b1 = parameters[\"b1\"]\n",
        "          W2 = parameters[\"W2\"]\n",
        "          b2 = parameters[\"b2\"]\n",
        "\n",
        "                             
        "          z1 = np.dot(X, W1) + b1\n",
        "\n",
        "                                          
        "          a1 = sigmoid(z1)\n",
        "\n",
        "                                                     ,
        "          z2 = np.dot(a1, W2) + b2\n",
        "\n",
        "                                                                 
        "          y_hat = sigmoid(z2)\n",
        "\n",
        "          cache = {\n",
        "              \"z1\": z1,\n",
        "              \"a1\": a1,\n",
        "              \"z2\": z2,\n",
        "              \"y_hat\": y_hat\n",
        "          }\n",
        "\n",
        "          return y_hat, cache"
      ],
      "metadata": {
        "id": "oQqLTF-f5wv-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(y, y_hat):\n",
        "      n = y.shape[0]   # number of samples\n",
        "      loss = (1/n) * np.sum((y - y_hat) ** 2)\n",
        "      return loss"
      ],
      "metadata": {
        "id": "ybLoKH-560tN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, y, parameters, cache):\n",
        "\n",
        "          W1 = parameters[\"W1\"]\n",
        "          W2 = parameters[\"W2\"]\n",
        "\n",
        "          z1 = cache[\"z1\"]\n",
        "          a1 = cache[\"a1\"]\n",
        "          z2 = cache[\"z2\"]\n",
        "          y_hat = cache[\"y_hat\"]\n",
        "\n",
        "          n = X.shape[0]\n",
        "\n",
        "                                                 
        "          dL_dyhat = -(2/n) * (y - y_hat)\n",
        "\n",
        "                                                             
        "          dyhat_dz2 = sigmoid_derivative(z2)\n",
        "          dz2 = dL_dyhat * dyhat_dz2\n",
        "\n",
        "          dW2 = np.dot(a1.T, dz2)\n",
        "          db2 = np.sum(dz2, axis=0, keepdims=True)\n",
        "\n",
        "                                                                                         
        "          dz1 = np.dot(dz2, W2.T) * sigmoid_derivative(z1)\n",
        "\n",
        "                                                                                                     
        "          dW1 = np.dot(X.T, dz1)\n",
        "          db1 = np.sum(dz1, axis=0, keepdims=True)\n",
        "\n",
        "          gradients = {\n",
        "                       \"dW1\": dW1,\n",
        "                       \"db1\": db1,\n",
        "                       \"dW2\": dW2,\n",
        "                       \"db2\": db2}\n",
        "          return gradients"
      ],
      "metadata": {
        "id": "v0nr4rYz7G97"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(parameters, gradients, learning_rate):\n",
        "\n",
        "          # Update output layer\n",
        "              parameters[\"W2\"] = parameters[\"W2\"] - learning_rate * gradients[\"dW2\"]\n",
        "              parameters[\"b2\"] = parameters[\"b2\"] - learning_rate * gradients[\"db2\"]\n",
        "\n",
        "                          # Update hidden layer\n",
        "              parameters[\"W1\"] = parameters[\"W1\"] - learning_rate * gradients[\"dW1\"]\n",
        "              parameters[\"b1\"] = parameters[\"b1\"] - learning_rate * gradients[\"db1\"]\n",
        "\n",
        "              return parameters\n"
      ],
      "metadata": {
        "id": "c1YKusGb9QMA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, y, n_input, n_hidden, n_output, epochs=1000, learning_rate=0.01):\n",
        "\n",
        "          # Initialize parameters\n",
        "              parameters = initialize_parameters(n_input, n_hidden, n_output)\n",
        "\n",
        "              losses = []\n",
        "\n",
        "              for epoch in range(epochs):\n",
        "\n",
        "                                              # Step 5: Forward Propagation\n",
        "                      y_hat, cache = forward_propagation(X, parameters)\n",
        "\n",
        "                                                                      
        "                      loss = compute_loss(y, y_hat)\n",
        "                      losses.append(loss)\n",
        "\n",
        "                                                                                                      
        "                      gradients = backpropagation(X, y, parameters, cache)\n",
        "\n",
        "                                                                                                                            
        "                      parameters = update_parameters(parameters, gradients, learning_rate)\n",
        "\n",
        "                                                                                                                                                     
        "                      if epoch % 100 == 0:\n",
        "                               print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "                               return parameters, losses\n"
      ],
      "metadata": {
        "id": "XK9-RK-C9cgi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_loss(losses):\n",
        "    plt.plot(losses)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Loss vs Epochs\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_1wAAyU89v4J"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_activation():\n",
        "      x = np.linspace(-10, 10, 100)\n",
        "      y = 1 / (1 + np.exp(-x))  # Sigmoid\n",
        "\n",
        "      plt.plot(x, y)\n",
        "      plt.xlabel(\"Input\")\n",
        "      plt.ylabel(\"Sigmoid Output\")\n",
        "      plt.title(\"Sigmoid Activation Function\")\n",
        "      plt.grid(True)\n",
        "      plt.show()\n"
      ],
      "metadata": {
        "id": "4qXiUkPF9_oe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_landscape(X, y, parameters):\n",
        "\n",
        "          W1_original = parameters[\"W1\"].copy()\n",
        "\n",
        "          w1_range = np.linspace(-2, 2, 50)\n",
        "          w2_range = np.linspace(-2, 2, 50)\n",
        "\n",
        "          loss_surface = np.zeros((50, 50))\n",
        "\n",
        "          for i in range(50):\n",
        "             for j in range(50):\n",
        "                     parameters[\"W1\"][0,0] = w1_range[i]\n",
        "                     parameters[\"W1\"][1,0] = w2_range[j]\n",
        "\n",
        "                     y_hat, _ = forward_propagation(X, parameters)\n",
        "                     loss_surface[i, j] = compute_loss(y, y_hat)\n",
        "\n",
        "                                                                                                                  
        "          parameters[\"W1\"] = W1_original\n",
        "\n",
        "          W1_grid, W2_grid = np.meshgrid(w1_range, w2_range)\n",
        "\n",
        "          from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "          fig = plt.figure()\n",
        "          ax = fig.add_subplot(111, projection='3d')\n",
        "          ax.plot_surface(W1_grid, W2_grid, loss_surface)\n",
        "\n",
        "          ax.set_xlabel(\"Weight 1\")\n",
        "          ax.set_ylabel(\"Weight 2\")\n",
        "          ax.set_zlabel(\"Loss\")\n",
        "          ax.set_title(\"Loss Landscape\")\n",
        "\n",
        "          plt.show()\n"
      ],
      "metadata": {
        "id": "gAaTOa8c-PXx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X_test, parameters):\n",
        "\n",
        "          # Forward propagation\n",
        "              y_hat, _ = forward_propagation(X_test, parameters)\n",
        "\n",
        "              return y_hat\n"
      ],
      "metadata": {
        "id": "h0u2F2ud_HLJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_class(X_test, parameters, threshold=0.5):\n",
        "\n",
        "          y_hat, _ = forward_propagation(X_test, parameters)\n",
        "\n",
        "          predictions = (y_hat > threshold).astype(int)\n",
        "\n",
        "          return predictions\n"
      ],
      "metadata": {
        "id": "n5A1cc56_ZNC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([[1, 0]])\n",
        "\n",
        "n_input = X.shape[1]\n",
        "n_hidden = 4\n",
        "n_output = y.shape[1]\n",
        "\n",
        "params, _ = train(X, y, n_input, n_hidden, n_output,\n",
        "                  epochs=10000, learning_rate=0.1)\n",
        "\n",
        "prob = predict(X_test, params)\n",
        "print(\"Predicted Probability:\", prob)\n",
        "\n",
        "pred = predict_class(X_test, params)\n",
        "print(\"Predicted Class:\", pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhleaynuBAFL",
        "outputId": "ba1e9d48-c351-4b6a-aef8-d4e40b83f812"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.2500\n",
            "Predicted Probability: [[0.49751386]]\n",
            "Predicted Class: [[0]]\n"
          ]
        }
      ]
    }
  ]
}
